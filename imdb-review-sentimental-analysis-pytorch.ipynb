{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-07T11:26:22.571931Z",
     "iopub.status.busy": "2024-10-07T11:26:22.571689Z",
     "iopub.status.idle": "2024-10-07T11:26:22.793785Z",
     "shell.execute_reply": "2024-10-07T11:26:22.792954Z",
     "shell.execute_reply.started": "2024-10-07T11:26:22.571889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:27:12.886345Z",
     "iopub.status.busy": "2024-10-07T11:27:12.886017Z",
     "iopub.status.idle": "2024-10-07T11:27:14.088674Z",
     "shell.execute_reply": "2024-10-07T11:27:14.087900Z",
     "shell.execute_reply.started": "2024-10-07T11:27:12.886290Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "test_data_sub=pd.read_csv('../input/test.csv')\n",
    "train_data=pd.read_csv('../input/train.csv')\n",
    "reviews=train_data['review'].get_values()\n",
    "labels=train_data['sentiment'].get_values()\n",
    "input_test=test_data_sub['review'].get_values()\n",
    "y_test=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:27:25.870071Z",
     "iopub.status.busy": "2024-10-07T11:27:25.869776Z",
     "iopub.status.idle": "2024-10-07T11:27:27.403218Z",
     "shell.execute_reply": "2024-10-07T11:27:27.402352Z",
     "shell.execute_reply.started": "2024-10-07T11:27:25.870028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:27:35.822546Z",
     "iopub.status.busy": "2024-10-07T11:27:35.822168Z",
     "iopub.status.idle": "2024-10-07T11:27:35.833845Z",
     "shell.execute_reply": "2024-10-07T11:27:35.833005Z",
     "shell.execute_reply.started": "2024-10-07T11:27:35.822483Z"
    }
   },
   "outputs": [],
   "source": [
    "appos = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:27:40.229711Z",
     "iopub.status.busy": "2024-10-07T11:27:40.229372Z",
     "iopub.status.idle": "2024-10-07T11:27:40.238273Z",
     "shell.execute_reply": "2024-10-07T11:27:40.237483Z",
     "shell.execute_reply.started": "2024-10-07T11:27:40.229665Z"
    }
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def review_formatting(reviews):\n",
    "    all_reviews=list()\n",
    "    for text in reviews:\n",
    "        lower_case = text.lower()\n",
    "        words = lower_case.split()\n",
    "        reformed = [appos[word] if word in appos else word for word in words]\n",
    "        reformed_test=list()\n",
    "        for word in reformed:\n",
    "            if word not in stop_words:\n",
    "                reformed_test.append(word)\n",
    "        reformed = \" \".join(reformed_test) \n",
    "        punct_text = \"\".join([ch for ch in reformed if ch not in punctuation])\n",
    "        all_reviews.append(punct_text)\n",
    "    all_text = \" \".join(all_reviews)\n",
    "    all_words = all_text.split()\n",
    "    return all_reviews, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:27:44.454581Z",
     "iopub.status.busy": "2024-10-07T11:27:44.454239Z",
     "iopub.status.idle": "2024-10-07T11:28:08.236811Z",
     "shell.execute_reply": "2024-10-07T11:28:08.236144Z",
     "shell.execute_reply.started": "2024-10-07T11:27:44.454535Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "# Count all the words using Counter Method\n",
    "all_reviews, all_words=review_formatting(reviews)\n",
    "count_words = Counter(all_words)\n",
    "total_words=len(all_words)\n",
    "sorted_words=count_words.most_common(total_words)\n",
    "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:28:08.238945Z",
     "iopub.status.busy": "2024-10-07T11:28:08.238661Z",
     "iopub.status.idle": "2024-10-07T11:28:08.247347Z",
     "shell.execute_reply": "2024-10-07T11:28:08.246346Z",
     "shell.execute_reply.started": "2024-10-07T11:28:08.238886Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_reviews(reviews):\n",
    "    \"\"\"\n",
    "    encode_reviews function will encodes review in to array of numbers\n",
    "    \"\"\"\n",
    "    all_reviews=list()\n",
    "    for text in reviews:\n",
    "        text = text.lower()\n",
    "        text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "        all_reviews.append(text)\n",
    "    encoded_reviews=list()\n",
    "    for review in all_reviews:\n",
    "        encoded_review=list()\n",
    "        for word in review.split():\n",
    "            if word not in vocab_to_int.keys():\n",
    "                encoded_review.append(0)\n",
    "            else:\n",
    "                encoded_review.append(vocab_to_int[word])\n",
    "        encoded_reviews.append(encoded_review)\n",
    "    return encoded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:28:08.249148Z",
     "iopub.status.busy": "2024-10-07T11:28:08.248786Z",
     "iopub.status.idle": "2024-10-07T11:28:08.259491Z",
     "shell.execute_reply": "2024-10-07T11:28:08.258828Z",
     "shell.execute_reply.started": "2024-10-07T11:28:08.249093Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sequences(encoded_reviews, sequence_length=250):\n",
    "    ''' \n",
    "    Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "    \n",
    "    for i, review in enumerate(encoded_reviews):\n",
    "        review_len=len(review)\n",
    "        if (review_len<=sequence_length):\n",
    "            zeros=list(np.zeros(sequence_length-review_len))\n",
    "            new=zeros+review\n",
    "        else:\n",
    "            new=review[:sequence_length]\n",
    "        features[i,:]=np.array(new)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:28:08.273126Z",
     "iopub.status.busy": "2024-10-07T11:28:08.272885Z",
     "iopub.status.idle": "2024-10-07T11:28:08.281696Z",
     "shell.execute_reply": "2024-10-07T11:28:08.281108Z",
     "shell.execute_reply.started": "2024-10-07T11:28:08.273079Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    \"\"\"\n",
    "    This Function will tranform reviews in to model readable form\n",
    "    \"\"\"\n",
    "    formated_reviews, all_words = review_formatting(reviews)\n",
    "    encoded_reviews=encode_reviews(formated_reviews)\n",
    "    features=pad_sequences(encoded_reviews, 250)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:28:19.936160Z",
     "iopub.status.busy": "2024-10-07T11:28:19.935875Z",
     "iopub.status.idle": "2024-10-07T11:28:30.949010Z",
     "shell.execute_reply": "2024-10-07T11:28:30.948288Z",
     "shell.execute_reply.started": "2024-10-07T11:28:19.936118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    35000.000000\n",
       "mean       230.740571\n",
       "std        171.009115\n",
       "min          8.000000\n",
       "25%        126.000000\n",
       "50%        173.000000\n",
       "75%        281.000000\n",
       "max       2122.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyse Review length\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "encoded_reviews=encode_reviews(reviews)\n",
    "review_len=[len(encoded_review) for encoded_review in encoded_reviews]\n",
    "pd.Series(review_len).hist()\n",
    "plt.show()\n",
    "pd.Series(review_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:28:30.951712Z",
     "iopub.status.busy": "2024-10-07T11:28:30.951362Z",
     "iopub.status.idle": "2024-10-07T11:29:03.473762Z",
     "shell.execute_reply": "2024-10-07T11:29:03.473040Z",
     "shell.execute_reply.started": "2024-10-07T11:28:30.951651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500 3500\n"
     ]
    }
   ],
   "source": [
    "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
    "features=preprocess(reviews)\n",
    "train_x=features[:int(0.90*len(features))]\n",
    "train_y=labels[:int(0.90*len(features))]\n",
    "valid_x=features[int(0.90*len(features)):]\n",
    "valid_y=labels[int(0.90*len(features)):]\n",
    "print(len(train_y), len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:29:03.475570Z",
     "iopub.status.busy": "2024-10-07T11:29:03.475241Z",
     "iopub.status.idle": "2024-10-07T11:29:04.632630Z",
     "shell.execute_reply": "2024-10-07T11:29:04.631868Z",
     "shell.execute_reply.started": "2024-10-07T11:29:03.475519Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#create Tensor Dataset\n",
    "train_data=TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data=TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "\n",
    "#dataloader\n",
    "batch_size=50\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:29:04.670280Z",
     "iopub.status.busy": "2024-10-07T11:29:04.670013Z",
     "iopub.status.idle": "2024-10-07T11:29:04.682484Z",
     "shell.execute_reply": "2024-10-07T11:29:04.681682Z",
     "shell.execute_reply.started": "2024-10-07T11:29:04.670218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 250])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,  1912,     8,   155],\n",
      "        [    0,     0,     0,  ...,  7604,  2396, 20517],\n",
      "        [    0,     0,     0,  ...,    72,   280,   158],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,  1881,   367,   785],\n",
      "        [    0,     0,     0,  ...,     5,   530,  2163],\n",
      "        [    0,     0,     0,  ...,    15,    23,     4]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:29:04.684431Z",
     "iopub.status.busy": "2024-10-07T11:29:04.684163Z",
     "iopub.status.idle": "2024-10-07T11:29:04.702649Z",
     "shell.execute_reply": "2024-10-07T11:29:04.701954Z",
     "shell.execute_reply.started": "2024-10-07T11:29:04.684388Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    " \n",
    "class SentimentalLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        #Embedding and LSTM layers\n",
    "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        #dropout layer\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "        \n",
    "        #Linear and sigmoid layer\n",
    "        self.fc1=nn.Linear(hidden_dim, 64)\n",
    "        self.fc2=nn.Linear(64, 16)\n",
    "        self.fc3=nn.Linear(16,output_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size=x.size()\n",
    "        \n",
    "        #Embadding and LSTM output\n",
    "        embedd=self.embedding(x)\n",
    "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
    "        \n",
    "        #stack up the lstm output\n",
    "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        #dropout and fully connected layers\n",
    "        out=self.dropout(lstm_out)\n",
    "        out=self.fc1(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc3(out)\n",
    "        sig_out=self.sigmoid(out)\n",
    "        \n",
    "        sig_out=sig_out.view(batch_size, -1)\n",
    "        sig_out=sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:29:05.377987Z",
     "iopub.status.busy": "2024-10-07T11:29:05.377747Z",
     "iopub.status.idle": "2024-10-07T11:29:06.047371Z",
     "shell.execute_reply": "2024-10-07T11:29:06.046635Z",
     "shell.execute_reply.started": "2024-10-07T11:29:05.377950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentalLSTM(\n",
      "  (embedding): Embedding(148794, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:31:24.439827Z",
     "iopub.status.busy": "2024-10-07T11:31:24.439549Z",
     "iopub.status.idle": "2024-10-07T11:33:37.155727Z",
     "shell.execute_reply": "2024-10-07T11:33:37.155068Z",
     "shell.execute_reply.started": "2024-10-07T11:31:24.439775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3... Step: 100... Loss: 0.621151... Val Loss: 0.570603\n",
      "Epoch: 1/3... Step: 200... Loss: 0.604785... Val Loss: 0.524907\n",
      "Epoch: 1/3... Step: 300... Loss: 0.574789... Val Loss: 0.483864\n",
      "Epoch: 1/3... Step: 400... Loss: 0.480728... Val Loss: 0.523330\n",
      "Epoch: 1/3... Step: 500... Loss: 0.346921... Val Loss: 0.427481\n",
      "Epoch: 1/3... Step: 600... Loss: 0.547650... Val Loss: 0.399887\n",
      "Epoch: 2/3... Step: 700... Loss: 0.443517... Val Loss: 0.406617\n",
      "Epoch: 2/3... Step: 800... Loss: 0.336680... Val Loss: 0.392442\n",
      "Epoch: 2/3... Step: 900... Loss: 0.370986... Val Loss: 0.377247\n",
      "Epoch: 2/3... Step: 1000... Loss: 0.451816... Val Loss: 0.364535\n",
      "Epoch: 2/3... Step: 1100... Loss: 0.290597... Val Loss: 0.344203\n",
      "Epoch: 2/3... Step: 1200... Loss: 0.344928... Val Loss: 0.344820\n",
      "Epoch: 3/3... Step: 1300... Loss: 0.125864... Val Loss: 0.385078\n",
      "Epoch: 3/3... Step: 1400... Loss: 0.248791... Val Loss: 0.343410\n",
      "Epoch: 3/3... Step: 1500... Loss: 0.323874... Val Loss: 0.340924\n",
      "Epoch: 3/3... Step: 1600... Loss: 0.222736... Val Loss: 0.334302\n",
      "Epoch: 3/3... Step: 1700... Loss: 0.344383... Val Loss: 0.352298\n",
      "Epoch: 3/3... Step: 1800... Loss: 0.407065... Val Loss: 0.356368\n"
     ]
    }
   ],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()  \n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:35:38.133680Z",
     "iopub.status.busy": "2024-10-07T11:35:38.133327Z",
     "iopub.status.idle": "2024-10-07T11:37:39.427696Z",
     "shell.execute_reply": "2024-10-07T11:37:39.427025Z",
     "shell.execute_reply.started": "2024-10-07T11:35:38.133618Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(input_test):\n",
    "    output_list=list()\n",
    "    batch_size=50   \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        test_review=preprocess(input_test)\n",
    "        for review in test_review:\n",
    "            # convert to tensor to pass into your model\n",
    "            feature_tensor = torch.from_numpy(review).view(1,-1)\n",
    "            if(train_on_gpu):\n",
    "                feature_tensor= feature_tensor.cuda()\n",
    "            batch_size = feature_tensor.size(0)\n",
    "            # initialize hidden state\n",
    "            h = net.init_hidden(batch_size)\n",
    "            # get the output from the model\n",
    "            output, h = net(feature_tensor, h)\n",
    "            pred = torch.round(output.squeeze()) \n",
    "            output_list.append(pred)\n",
    "        labels=[int(i.data.cpu().numpy()) for i in output_list]\n",
    "        return labels\n",
    "labels=test_model(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:37:39.429454Z",
     "iopub.status.busy": "2024-10-07T11:37:39.429143Z",
     "iopub.status.idle": "2024-10-07T11:37:41.496167Z",
     "shell.execute_reply": "2024-10-07T11:37:41.495314Z",
     "shell.execute_reply.started": "2024-10-07T11:37:39.429400Z"
    }
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['Id'] = test_data_sub['Id']\n",
    "output['sentiment'] = labels\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T11:37:41.499466Z",
     "iopub.status.busy": "2024-10-07T11:37:41.499091Z",
     "iopub.status.idle": "2024-10-07T11:37:41.523990Z",
     "shell.execute_reply": "2024-10-07T11:37:41.523302Z",
     "shell.execute_reply.started": "2024-10-07T11:37:41.499402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>35015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>35023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>35024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>35026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>35029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>49970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>49971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>49972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>49973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14974</th>\n",
       "      <td>49974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>49975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>49976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>49977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>49978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>49979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>49980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>49981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>49982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>49983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>49984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>49985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>49986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>49987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>49988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>49989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>49990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>49991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>49992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>49993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>49994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>49995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>49996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>49997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>49998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>49999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  sentiment\n",
       "0      35000          1\n",
       "1      35001          1\n",
       "2      35002          0\n",
       "3      35003          0\n",
       "4      35004          0\n",
       "5      35005          1\n",
       "6      35006          1\n",
       "7      35007          1\n",
       "8      35008          1\n",
       "9      35009          0\n",
       "10     35010          1\n",
       "11     35011          1\n",
       "12     35012          1\n",
       "13     35013          1\n",
       "14     35014          0\n",
       "15     35015          1\n",
       "16     35016          1\n",
       "17     35017          1\n",
       "18     35018          1\n",
       "19     35019          0\n",
       "20     35020          1\n",
       "21     35021          1\n",
       "22     35022          1\n",
       "23     35023          0\n",
       "24     35024          1\n",
       "25     35025          1\n",
       "26     35026          0\n",
       "27     35027          0\n",
       "28     35028          1\n",
       "29     35029          1\n",
       "...      ...        ...\n",
       "14970  49970          1\n",
       "14971  49971          1\n",
       "14972  49972          0\n",
       "14973  49973          1\n",
       "14974  49974          1\n",
       "14975  49975          1\n",
       "14976  49976          0\n",
       "14977  49977          1\n",
       "14978  49978          1\n",
       "14979  49979          1\n",
       "14980  49980          1\n",
       "14981  49981          1\n",
       "14982  49982          0\n",
       "14983  49983          1\n",
       "14984  49984          1\n",
       "14985  49985          0\n",
       "14986  49986          0\n",
       "14987  49987          1\n",
       "14988  49988          0\n",
       "14989  49989          0\n",
       "14990  49990          1\n",
       "14991  49991          0\n",
       "14992  49992          1\n",
       "14993  49993          1\n",
       "14994  49994          1\n",
       "14995  49995          0\n",
       "14996  49996          0\n",
       "14997  49997          1\n",
       "14998  49998          1\n",
       "14999  49999          0\n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 588428,
     "sourceId": 15339,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 28772,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
